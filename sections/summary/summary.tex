\sommario

In this work we investigate the challenges of immersive AR by means of a stereoscopic, wide field-of-view (FOV) head-mounted display (HMD) and subsequent realization of see-through with a stereo camera rig. Nowadays Virtual Reality (VR) brings virtual world closer to realistic experience while modern computer vision offers better digital understanding of reality. Stereoscopy is a veteran discipline of which both make use but not much has been done to fill the gap between the two. By borrowing both the perceptual aspects of immersive virtual reality and image analysis and elaboration from computer vision, we attempt to successfully blend synthetic and real images that can possibly interact and bond with Augmented Reality (AR). We present a set of strategies which proved to help healing the encountered latency, perception and geometrical discrepancies and tested them on Oculus Rift DK2 and a custom stereo camera rig. As a result, a final representation model and architecture was developed to decouple vision, stereoscopy and computer graphics implementation aspects and a configurable solution was provided to coexist in one application.